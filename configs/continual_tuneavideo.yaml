pretrained_model_path: "./checkpoints/stable-diffusion-v1-4"
output_dir: "./outputs"

train_data:
  pretrained_model_path: "./checkpoints/stable-diffusion-v1-4"
  video_dir: "data/train_videos"
  prompt_file: "data/train_captions.txt"
  n_sample_frames: 24
  width: 512
  height: 512
  sample_start_idx: 0
  sample_frame_rate: 2

validation_data:
  prompts:
    - "a person riding a hoverboard on a wet street"
    - "a man playing violin with two men in a room"
    - "a group of people dancing in front of a building"
    - "a roller coaster with a blue sky and orange and purple colors"
  video_length: 24
  width: 512
  height: 512
  num_inference_steps: 50
  guidance_scale: 12.5
  use_inv_latent: True
  num_inv_steps: 50

learning_rate: 3e-5
train_batch_size: 1
num_steps_per_sample: 500
num_epochs: 1
checkpointing_steps: 1000
validation_steps: 100
trainable_modules:
  - "attn1.to_q"
  - "attn2.to_q"
  - "attn_temp"

seed: 33
mixed_precision: fp16
use_8bit_adam: False
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: True
